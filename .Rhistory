1-resid(fit)[1]/resno
head(hatvalues(fit))
sigma2<-
dev(fit)
sigma2<-sqrt(resid(fit))
sigma <- sqrt(deviance(fit)/df.residual(fit))
rstd<-resid(fit)/sigma*sqrt(1-hatvalues(fit))
rstd <- resid(fit)/(sigma * sqrt(1-hatvalues(fit)))
head(cbind(rstd, rstandard(fit)))
plot(fit, which=3)
plot(fit, which=2)
sigma1 <- sqrt(deviance(fitno)/df.residual(fitno))
resid(fit)[1]/(sigma1*sqrt(1-hatvalues(fit)[1]))
head(rstudent(fit))
dy<-predict(fitno, out2)-predict(fit, out2)
dy/2*sigma^2
sum(dy^2)/(2*sigma^2)
plot(fit, which=5)
makelms <- function(x1, x2, x3){
# Simulate a dependent variable, y, as x1
# plus a normally distributed error of mean 0 and
# standard deviation .3.
y <- x1 + rnorm(length(x1), sd = .3)
# Find the coefficient of x1 in 3 nested linear
# models, the first including only the predictor x1,
# the second x1 and x2, the third x1, x2, and x3.
c(coef(lm(y ~ x1))[2],
coef(lm(y ~ x1 + x2))[2],
coef(lm(y ~ x1 + x2 + x3))[2])
}
# Regressor generation process 1.
rgp1 <- function(){
print("Processing. Please wait.")
# number of samples per simulation
n <- 100
# number of simulations
nosim <- 1000
# set seed for reproducability
set.seed(4321)
# Point A
x1 <- rnorm(n)
x2 <- rnorm(n)
x3 <- rnorm(n)
# Point B
betas <- sapply(1 : nosim, function(i)makelms(x1, x2, x3))
round(apply(betas, 1, var), 5)
}
# Regressor generation process 2.
rgp1()
rgp2()
head(swiss)
msl-lm(Fertility ~ ., swiss)
msl<-lm(Fertility ~ ., swiss)
mdl<-lm(Fertility ~ ., swiss)
vif(mdl)
mdl<-lm(Fertility ~ Agriculture+Education+Catholic+Infant.Mortality, swiss)
mdl<-lm(Fertility ~ Agriculture+Education+Catholic+Infant.Mortality, swiss)
mdl2<-lm(Fertility ~ Agriculture+Education+Catholic+Infant.Mortality, swiss)
vif(mdl2)
x1c<-simbias()
apply(x1c,
| 1, mean)
apply(x1c, 1, mean)
fit1<-lm(Fertility~Agroculture,swiss)
fit1<-lm(Fertility~Agriculture,swiss)
fit3<-lm(Fertility~Agriculture+Examination+Education,swiss)
anova(fit1, fit3)
deviance(fit3)
d<-deviance(fit3)/43
n<-(deviance(fit1)-deviance(fit3)/(df(fit1)-df(fit3))
)
n<-(deviance(fit1)-deviance(fit3))/(df(fit1)-df(fit3))
df(fit3)
n<-(deviance(fit1)-deviance(fit3))/(summary(fit1)$df-summary(fit3)$df)
n <- (deviance(fit1) - deviance(fit3))/2
n/d
pf(n/d, 2, 43, lower.tail=FALSE)
shapiro.test(fit3$residuals)
anova(fit1, fit3, fit5, fit6)
ravenData
mdl<-glm(ravenWinNum ~ ravenScore,family,ravenData)
mdl<-glm(ravenWinNum ~ ravenScore,ravenData)
mdl<-glm(ravenWinNum ~ ravenScore,,ravenData)
mdl <- glm(ravenWinNum ~ ravenScore, family=binomial, data=ravenData)
lodds<-predict(mdl, data.frame(ravenScore=c(0, 3, 6))
)
exp(lodds)/(1+exp(lodds))
summary(mdl)
exp(confint(mdl))
anova(mdl)
qchisq(0.95, 1)
var(rpois(1000, 50))
head(hits)
class(hits[,'date'])
as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits).
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(onfint(mdl, 'date'))
exp(confint(mdl, 'date'))
which.max(hits[,'visits'])
hits[704,]
lambda<-mdl$fitted.values[704]
qpois(.95, lambda)
md2 <- glm(visits ~ date, poisson, hits)
mdl2 <- glm(formula = simplystats ~ date, family = poisson, data = hits, offset = log(visits + 1))
qpois(.95, mdl2$fitted.values[704])
install.packages("tufte-latex")
require(quantmod)
getSymbols("YHOO",src="google")
View(M)
View(YHOO)
getSymbols(’GE’,src=’yahoo’, from="2000-01-01", to="2009-12-30")
getSymbols(’GE’,src=’yahoo’, from="2000-01-01", to="2009-12-30")
getSymbols("GE",src="yahoo", from="2000-01-01", to="2009-12-30")
View(GE)
chartSeries(GE)
getSymbols("CABK",src="yahoo", from="2000-01-01", to="2009-12-30")
View(CABK)
getSymbols("CABK",src="yahoo", from="2010-01-01", to="2014-11-30")
View(CABK)
getSymbols("CABK",src="yahoo", from="2012-01-01", to="2014-11-30")
View(CABK)
getSymbols("BBVA",src="yahoo", from="2012-01-01", to="2014-11-30")
View(BBVA)
getSymbols("BBVA",src="yahoo", from="2012-01-01)
""
sdasdasd
))
)""
getSymbols("BBVA",src="yahoo", from="2012-01-01")
View(BBVA)
chartSeries(BBVA)
install.packages("caret")
library("caret", lib.loc="~/R/win-library/3.1")
install.packages("kernlab")
data(spam)
library("kernlab", lib.loc="~/R/win-library/3.1")
data(spam)
View(spam)
inTrain<-createDataPartition(y=spam$type, p=0.75, list=FALSE)
View(inTrain)
training<-spam[inTrain,]
View(training)
testing<-spam[-inTrain,]
dim(training)
set.seed(32343)
modelFit<-train(type ~., data=training,method='glm')
modelFit<-train(type ~., data=training,method='glm')
modelFit <- train(type ~., data=training,method='glm')
modelFit <- train(type ~., data=training, method="glm")
modelFit <- train(type ~., data=training, method="glm")
install.packages(c("BH", "car", "circlize", "digest", "GlobalOptions", "Hmisc", "jsonlite", "magrittr", "RColorBrewer", "RcppArmadillo", "RCurl", "reshape2"))
install.packages(c("BH", "car", "circlize", "digest", "GlobalOptions",
install.packages(c("BH", "car", "circlize", "digest", "GlobalOptions", "Hmisc", "jsonlite", "magrittr", "RColorBrewer", "RcppArmadillo", "RCurl", "reshape2"))
install.packages(c("BH", "car", "circlize", "digest", "GlobalOptions",
)
daf
install.packages(c("BH", "car", "circlize", "digest", "GlobalOptions", "Hmisc", "jsonlite", "magrittr", "RColorBrewer", "RcppArmadillo", "RCurl", "reshape2"))
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength,
p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
featurePlot(x = training[,c('Cement',
'BlastFurnaceSlag',
'FlyAsh',
'Water',
'Superplasticizer',
'CoarseAggregate',
'FineAggregate', 'Age')],
y = training$CompressiveStrength )
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength,
p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
qplot(Superplasticizer, data=training)
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
View(predictors)
adData = data.frame(diagnosis,predictors)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
View(predictors)
log(0)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
library("AGD", lib.loc="~/R/win-library/3.1")
missClass(trainSA[,10], predict(model, trainSA))
set.seed(13234)
model = train(trainSA[,-c(10,1,4,5)], trainSA[,10], method = "glm", family = "binomial")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
model = train(trainSA[,-c(10,1,4,5)], trainSA[,10], method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
model = train(trainSA[,-c(10,1,4,5)], trainSA[,10], method = "glm", family = "binomial")
library("caret", lib.loc="~/R/win-library/3.1")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
model = train(trainSA[,-c(10,1,4,5)], trainSA[,10], method = "glm", family = "binomial")
missClass(testSA[,10], predict(model, testSA))
missClass(trainSA[,10], predict(model, trainSA))
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training = segmentationOriginal[segmentationOriginal$Case == "Train",]
testing = segmentationOriginal[segmentationOriginal$Case == "Test",]
set.seed(125)
library(rpart)
fit = train(Class ~ ., data = training,method = "rpart")
plot(fit$finalModel, uniform = T)
text(fit$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
set.seed(727)
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
View(testing)
str(testing)
testing$classe
class(training$classe)
class(testing$classe)
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
testing$classe <- as.factor(testing$classe)
colSums(!is.na(testing[,-ncol(testing)])) == nrow(testing)
c((colSums(!is.na(testing[,-ncol(testing)])) == nrow(testing)))
sum(c((colSums(!is.na(testing[,-ncol(testing)])) == nrow(testing))))
predictors <- c((colSums(!is.na(testing[,-ncol(testing)])) == nrow(testing)))
training <- training[, predictors]
dim(training)
testing <- testing[, predictors]
dim(testing)
View(training)
View(testing)
View(training)
inTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
myTraining <- training[inTrain, ]; dim(myTraining)
myTesting <- training[-inTrain, ]; dim(myTesting)
modeltree <- train(classe ~., data=myTraining, method="rpart", trControl=fitControl)
modeltree <- train(classe ~., data=myTraining, method="rpart", trControl=fitControl)
modeltree <- train(classe ~., data=myTraining, method="rpart", trControl=fitControl)
modFit <- train(classe ~., method="rf", data=myTraining, trControl=trainControl(method='cv'), number=5, allowParallel=TRUE )
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
View(testing)
testing <- testing[,-1]
testing$classe <- as.factor(testing$classe)
View(testing)
testing$classe
training(classe)
training$classe
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
testing$classe <- as.factor(testing$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
predictors <- c((colSums(!is.na(testing[,-ncol(testing)])) == nrow(testing)))
training <- training[, predictors]
dim(training)
testing <- testing[, predictors]
dim(testing)
View(testing)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
predictors <- c((colSums(!is.na(testing[,-ncol(testing)])) == nrow(testing)))
training <- training[, predictors]
dim(training)
testing <- testing[, predictors]
dim(testing)
inTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
myTraining <- training[inTrain, ]; dim(myTraining)
myTesting <- training[-inTrain, ]; dim(myTesting)
inTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
myTraining <- training[inTrain, ]; dim(myTraining)
myTesting <- training[-inTrain, ]; dim(myTesting)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(modFitA1)
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
confusionMatrix(predictionsA1, myTesting$classe)
modFitB1 <- randomForest(classe ~. , data=myTraining)
modFitB1 <- randomForest(classe ~. , data=myTraining)
model <- randomForest(classe~.,data=training)
train(classe ~ ., data=DTrainCS, method='rf'))
train(classe ~ ., data=DTrainCS, method='rf')
train(classe ~ ., data=myTraining, method='rf')
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
apply(training,2,function(x) {sum(is.na(x))})
NAindex <- apply(testingRaw,2,function(x) {sum(is.na(x))})
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
trainingRaw <- training[,which(NAindex == 0)]
View(trainingRaw)
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
training <- training[,which(NAindex == 0)]
testing <- testing[,which(NAindex == 0)]
dim(training); dim(testing)
which(lapply(training, class) %in% "numeric")
nzv <- nearZeroVar(training,saveMetrics=TRUE)
nzv
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
training <- training[,which(NAindex == 0)]
testing <- testing[,which(NAindex == 0)]
dim(training); dim(testing)
nzv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testing,saveMetrics=TRUE)
training <- testing[,nzv$nzv==FALSE]
dim(training); dim(testing)
training <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
training <- training[,-1]
training$classe <- as.factor(training$classe)
testing <- read.csv(url("http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"), header=TRUE, as.is = TRUE, stringsAsFactors = FALSE, sep=',', na.strings=c("NA","#DIV/0!",""))
testing <- testing[,-1]
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
training <- training[,which(NAindex == 0)]
testing <- testing[,which(NAindex == 0)]
dim(training); dim(testing)
nzv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[,nzv$nzv==FALSE]
nzv <- nearZeroVar(testing,saveMetrics=TRUE)
testing <- testing[,nzv$nzv==FALSE]
dim(training); dim(testing)
inTrain <- createDataPartition(training$classe, p=0.7, list=FALSE)
myTraining <- training[inTrain, ]; dim(myTraining)
myTesting <- training[-inTrain, ]; dim(myTesting)
modFit <- train(classe ~., method="rf", data=myTraining, trControl=trainControl(method='cv'), number=5, allowParallel=TRUE )
randomForest(classe~.,data=training)
randomForest(classe~.,data=myTraining)
train(classe ~., method="rf", data=myTraining)
library(parallel)
library(doParallel)
install.packages("doParallel")
library(parallel)
library(doParallel)
fitControl <- trainControl(method="repeatedcv",
number=5,
repeats=1,
allowParallel=TRUE,
verboseIter=FALSE)
system.time(trainingModel <- train(classe ~ ., data=myTraining, method="rf"))
detectCores()
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
library(parallel)
library(doParallel)
registerDoParallel(makeCluster(detectCores() - 1))
fitControl <- trainControl(method="repeatedcv",
number=5,
repeats=1,
allowParallel=TRUE,
verboseIter=FALSE)
modFit <- train(classe ~., method="rf", data=myTraining, trControl=fitControl)
stopCluster(cl)
modFit
trainingPred <- predict(modFit, training)
confusionMatrix(trainingPred, training$classe)
trainingPred <- predict(modFit, myTraining)
confusionMatrix(trainingPred, myTraining[, classe])
testingPred <- predict(modFit, myTesting)
confusionMatrix(testingPred, myTesting[, classe])
trainingPred <- predict(modFit, myTraining)
confusionMatrix(trainingPred, myTraining$classe)
testingPred <- predict(modFit, myTesting)
confusionMatrix(testingPred, myTesting$classe)
varImp(modFit)
modFit$finalModel
save(modFit, file="TrainedModel.RData")
load(file="trainingModel.RData", verbose=TRUE)
load(file="TrainedModel.RData", verbose=TRUE)
hat <- predict(modFit, DTestCS)
hat <- predict(modFit, myTesting)
kk<-cbind(hat , myTesting)
hat <- predict(modFit,testing)
kk<-cbind(hat , testing)
kk
importance(modFit)
varImp(modFit)
modFit$finalModel
trainingPred <- predict(modFit, myTraining)
confusionMatrix(trainingPred, myTraining$classe)
testingPred <- predict(modFit, myTesting)
confusionMatrix(testingPred, myTesting$classe)
varImp(modFit)
modFit$finalModel
predict(modFit,testing)
testingPred <- predict(modFit, myTesting)
confusionMatrix(testingPred, myTesting$classe)
```
trainingPred <- predict(modFit, myTraining)
confusionMatrix(trainingPred, myTraining$classe)
testingPred <- predict(modFit, myTesting)
confusionMatrix(testingPred, myTesting$classe)
varImp(modFit)
modFit$finalModel
answers <- predict(modFit,testing)
answers
pwd()
getwd()
setwd("C:/Users/JoseVicente/Desktop/Data Science/Johns Hopkins/Practical Machine Learning/Week3/Proyecto")
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(answers)
cmrf <- confusionMatrix(testingPred, testing$classe)
testingPred <- predict(modFit, myTesting)
confusionMatrix(testingPred, myTesting$classe)
cmrf <- confusionMatrix(testingPred, myTesting$classe)
plot(cmrf$table, col = class_colors, main = paste("Random Forest Confusion Matrix: Accuracy=", round(cmrf$overall['Accuracy'], 2)))
classes <- unique(training$classe)
class_colors <- 1 + as.integer(classes)
plot(cmrf$table, col = class_colors, main = paste("Random Forest Confusion Matrix: Accuracy=", round(cmrf$overall['Accuracy'], 2)))
